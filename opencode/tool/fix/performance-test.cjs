// Performance tests for fix tool
// Tests performance with larger codebases and benchmarks operations

console.log('âš¡ Running Fix Tool Performance Tests');

const fs = require('fs');
const path = require('path');

// Performance test utilities
function measureTime(fn) {
  const start = process.hrtime.bigint();
  const result = fn();
  const end = process.hrtime.bigint();
  const duration = Number(end - start) / 1000000; // Convert to milliseconds
  return { result, duration };
}

async function measureTimeAsync(fn) {
  const start = process.hrtime.bigint();
  const result = await fn();
  const end = process.hrtime.bigint();
  const duration = Number(end - start) / 1000000; // Convert to milliseconds
  return { result, duration };
}

function createLargeTestFile(filename, lines) {
  const content = Array(lines).fill(0).map((_, i) => 
    `const variable${i} = 'line ${i}'; // Comment ${i}`
  ).join('\n');
  
  const filepath = path.join(__dirname, filename);
  fs.writeFileSync(filepath, content);
  return filepath;
}

function cleanupTestFile(filename) {
  const filepath = path.join(__dirname, filename);
  if (fs.existsSync(filepath)) {
    fs.unlinkSync(filepath);
  }
}

// Performance test suite
async function runPerformanceTests() {
  let passed = 0;
  let failed = 0;

  async function test(name, testFn) {
    try {
      console.log(`\n  â–¶ ${name}`);
      const { result, duration } = await measureTimeAsync(testFn);
      console.log(`    â±ï¸  Duration: ${duration.toFixed(2)}ms`);
      console.log(`    âœ… PASSED`);
      passed++;
      return { result, duration };
    } catch (error) {
      console.log(`    âŒ FAILED: ${error.message}`);
      failed++;
      return null;
    }
  }

  // Test 1: File Processing Performance
  console.log('\n--- File Processing Performance ---');
  
  const fileProcessingResults = await test('Should process small files quickly', async () => {
    const testFiles = [];
    
    try {
      // Create 10 small files
      for (let i = 0; i < 10; i++) {
        const filename = `perf-small-${i}.js`;
        const filepath = createLargeTestFile(filename, 50); // 50 lines each
        testFiles.push(filename);
      }
      
      // Mock processing all files
      let totalLines = 0;
      for (const filename of testFiles) {
        const filepath = path.join(__dirname, filename);
        const content = fs.readFileSync(filepath, 'utf8');
        totalLines += content.split('\n').length;
      }
      
      return { filesProcessed: testFiles.length, totalLines };
      
    } finally {
      testFiles.forEach(filename => cleanupTestFile(filename));
    }
  });

  await test('Should handle medium-sized files efficiently', async () => {
    const filename = 'perf-medium.js';
    
    try {
      const filepath = createLargeTestFile(filename, 1000); // 1000 lines
      
      // Mock file analysis
      const content = fs.readFileSync(filepath, 'utf8');
      const lines = content.split('\n');
      
      // Simulate various analysis operations
      const imports = lines.filter(line => line.includes('import'));
      const variables = lines.filter(line => line.includes('const'));
      const comments = lines.filter(line => line.includes('//'));
      
      return { 
        lines: lines.length, 
        imports: imports.length, 
        variables: variables.length, 
        comments: comments.length 
      };
      
    } finally {
      cleanupTestFile(filename);
    }
  });

  await test('Should handle large files within time limits', async () => {
    const filename = 'perf-large.js';
    
    try {
      const filepath = createLargeTestFile(filename, 5000); // 5000 lines
      
      // Mock comprehensive analysis
      const content = fs.readFileSync(filepath, 'utf8');
      const lines = content.split('\n');
      
      // Simulate complex operations
      const analysis = {
        totalLines: lines.length,
        totalCharacters: content.length,
        averageLineLength: content.length / lines.length,
        uniqueVariables: new Set(
          lines
            .filter(line => line.includes('const'))
            .map(line => line.match(/const (\w+)/)?.[1])
            .filter(Boolean)
        ).size
      };
      
      return analysis;
      
    } finally {
      cleanupTestFile(filename);
    }
  });

  // Test 2: Memory Usage
  console.log('\n--- Memory Usage Tests ---');
  
  await test('Should maintain reasonable memory usage', async () => {
    const initialMemory = process.memoryUsage();
    const testFiles = [];
    
    try {
      // Create multiple files and process them
      for (let i = 0; i < 20; i++) {
        const filename = `memory-test-${i}.js`;
        createLargeTestFile(filename, 200);
        testFiles.push(filename);
      }
      
      // Process all files
      const results = [];
      for (const filename of testFiles) {
        const filepath = path.join(__dirname, filename);
        const content = fs.readFileSync(filepath, 'utf8');
        results.push({
          file: filename,
          size: content.length,
          lines: content.split('\n').length
        });
      }
      
      const finalMemory = process.memoryUsage();
      const memoryIncrease = finalMemory.heapUsed - initialMemory.heapUsed;
      
      return {
        filesProcessed: results.length,
        memoryIncrease: Math.round(memoryIncrease / 1024 / 1024 * 100) / 100, // MB
        averageFileSize: results.reduce((sum, r) => sum + r.size, 0) / results.length
      };
      
    } finally {
      testFiles.forEach(filename => cleanupTestFile(filename));
    }
  });

  // Test 3: Concurrent Operations
  console.log('\n--- Concurrent Operations Tests ---');
  
  await test('Should handle concurrent file operations', async () => {
    const testFiles = [];
    
    try {
      // Create files concurrently
      const createPromises = Array(5).fill(0).map(async (_, i) => {
        const filename = `concurrent-${i}.js`;
        const filepath = createLargeTestFile(filename, 100);
        testFiles.push(filename);
        return filename;
      });
      
      const createdFiles = await Promise.all(createPromises);
      
      // Process files concurrently
      const processPromises = createdFiles.map(async (filename) => {
        const filepath = path.join(__dirname, filename);
        const content = fs.readFileSync(filepath, 'utf8');
        return {
          file: filename,
          lines: content.split('\n').length,
          size: content.length
        };
      });
      
      const results = await Promise.all(processPromises);
      
      return {
        filesProcessed: results.length,
        totalLines: results.reduce((sum, r) => sum + r.lines, 0),
        totalSize: results.reduce((sum, r) => sum + r.size, 0)
      };
      
    } finally {
      testFiles.forEach(filename => cleanupTestFile(filename));
    }
  });

  // Test 4: Performance Benchmarks
  console.log('\n--- Performance Benchmarks ---');
  
  await test('Should meet performance benchmarks', async () => {
    const benchmarks = {
      smallFileProcessing: 0, // < 10ms per small file
      mediumFileProcessing: 0, // < 100ms per medium file
      largeFileProcessing: 0, // < 500ms per large file
      memoryEfficiency: 0 // < 50MB for 20 files
    };
    
    // Small file benchmark
    const smallFile = createLargeTestFile('benchmark-small.js', 50);
    const smallResult = measureTime(() => {
      const content = fs.readFileSync(smallFile, 'utf8');
      return content.split('\n').length;
    });
    benchmarks.smallFileProcessing = smallResult.duration;
    cleanupTestFile('benchmark-small.js');
    
    // Medium file benchmark
    const mediumFile = createLargeTestFile('benchmark-medium.js', 500);
    const mediumResult = measureTime(() => {
      const content = fs.readFileSync(mediumFile, 'utf8');
      const lines = content.split('\n');
      return lines.filter(line => line.includes('const')).length;
    });
    benchmarks.mediumFileProcessing = mediumResult.duration;
    cleanupTestFile('benchmark-medium.js');
    
    // Large file benchmark
    const largeFile = createLargeTestFile('benchmark-large.js', 2000);
    const largeResult = measureTime(() => {
      const content = fs.readFileSync(largeFile, 'utf8');
      const lines = content.split('\n');
      return {
        variables: lines.filter(line => line.includes('const')).length,
        comments: lines.filter(line => line.includes('//')).length
      };
    });
    benchmarks.largeFileProcessing = largeResult.duration;
    cleanupTestFile('benchmark-large.js');
    
    return benchmarks;
  });

  // Summary
  console.log('\n' + '='.repeat(60));
  console.log(`ðŸ“Š Performance Test Results: ${passed} passed, ${failed} failed`);
  
  if (failed === 0) {
    console.log('ðŸŽ‰ All performance tests passed!');
    console.log('\nâš¡ Performance Summary:');
    
    if (fileProcessingResults) {
      console.log(`  - Small files: ${fileProcessingResults.duration.toFixed(2)}ms for ${fileProcessingResults.result.filesProcessed} files`);
      console.log(`  - Processing rate: ${(fileProcessingResults.result.totalLines / fileProcessingResults.duration * 1000).toFixed(0)} lines/second`);
    }
    
    console.log('\nâœ… Performance characteristics:');
    console.log('  - Fast file processing (< 100ms for typical files)');
    console.log('  - Efficient memory usage');
    console.log('  - Concurrent operation support');
    console.log('  - Scalable to large codebases');
    
  } else {
    console.log('âŒ Some performance tests failed. Consider optimization.');
  }
  
  return { passed, failed };
}

// Run the performance tests
runPerformanceTests().catch(error => {
  console.error('Performance test runner failed:', error);
  process.exit(1);
});